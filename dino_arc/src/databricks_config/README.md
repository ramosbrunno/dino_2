# Databricks Configuration Scripts

Este diret√≥rio cont√©m scripts para configura√ß√£o autom√°tica do Databricks Unity Catalog e recursos Serverless ap√≥s o deploy da infraestrutura via Terraform.

## Arquivos

### 1. `unity_catalog_setup.py`
Script Python completo para configura√ß√£o do Unity Catalog e Serverless com classe reutiliz√°vel.

**Recursos:**
- ‚úÖ Cria√ß√£o do Unity Catalog Metastore
- ‚úÖ Atribui√ß√£o do Metastore ao Workspace
- ‚úÖ Cria√ß√£o de Catalog principal do projeto
- ‚úÖ Cria√ß√£o de Schemas (bronze, silver, gold, workspace)
- ‚úÖ Habilita√ß√£o do Serverless Compute
- ‚úÖ Cria√ß√£o de SQL Warehouse Serverless
- ‚úÖ Configura√ß√£o completa automatizada

**Depend√™ncias Python:**
```bash
pip install requests
```

### 2. `setup_databricks.sh`
Script Shell (Linux/MacOS) para configura√ß√£o via API REST do Databricks.

**Depend√™ncias:**
- `curl` - para requisi√ß√µes HTTP
- `jq` - para processamento JSON

**Instala√ß√£o das depend√™ncias:**
```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install curl jq

# MacOS
brew install curl jq

# CentOS/RHEL
sudo yum install curl jq
```

### 3. `setup_databricks.bat`
Script Batch (Windows) para configura√ß√£o via API REST do Databricks.

**Depend√™ncias:**
- `curl` - inclu√≠do no Windows 10+
- `jq` - download em https://stedolan.github.io/jq/download/

## Vari√°veis de Ambiente Necess√°rias

Todas as vers√µes dos scripts requerem as seguintes vari√°veis de ambiente:

```bash
# URL do workspace Databricks (obtido via Terraform output)
export DATABRICKS_WORKSPACE_URL="https://adb-1234567890123456.78.azuredatabricks.net"

# Token de acesso (gerado no Databricks ou via Service Principal)
export DATABRICKS_ACCESS_TOKEN="dapi1234567890abcdef..."

# Root storage para Unity Catalog (obtido via Terraform output)
export UNITY_CATALOG_STORAGE_ROOT="abfss://unity-catalog@storageaccount.dfs.core.windows.net/"

# ID do workspace Databricks (obtido via Terraform output)
export DATABRICKS_WORKSPACE_ID="1234567890123456"

# Par√¢metros do projeto
export PROJETO="meu-projeto"
export AMBIENTE="dev"
export AZURE_REGION="East US"
```

## Como Usar

### Op√ß√£o 1: Script Python
```bash
# Instalar depend√™ncias
pip install requests

# Configurar vari√°veis de ambiente
export DATABRICKS_WORKSPACE_URL="..."
export DATABRICKS_ACCESS_TOKEN="..."
# ... outras vari√°veis

# Executar
python unity_catalog_setup.py
```

### Op√ß√£o 2: Script Shell (Linux/MacOS)
```bash
# Dar permiss√£o de execu√ß√£o
chmod +x setup_databricks.sh

# Configurar vari√°veis de ambiente
export DATABRICKS_WORKSPACE_URL="..."
# ... outras vari√°veis

# Executar
./setup_databricks.sh
```

### Op√ß√£o 3: Script Batch (Windows)
```cmd
REM Configurar vari√°veis de ambiente
set DATABRICKS_WORKSPACE_URL=...
set DATABRICKS_ACCESS_TOKEN=...
REM ... outras vari√°veis

REM Executar
setup_databricks.bat
```

## Integra√ß√£o com Terraform

Os scripts podem ser executados automaticamente ap√≥s o deploy do Terraform usando `local-exec` provisioner:

```hcl
resource "null_resource" "databricks_config" {
  depends_on = [azurerm_databricks_workspace.main]

  provisioner "local-exec" {
    command = "python ${path.module}/databricks_config/unity_catalog_setup.py"
    
    environment = {
      DATABRICKS_WORKSPACE_URL      = "https://${azurerm_databricks_workspace.main.workspace_url}"
      DATABRICKS_ACCESS_TOKEN       = var.databricks_token
      UNITY_CATALOG_STORAGE_ROOT    = "abfss://${azurerm_storage_container.unity_catalog.name}@${azurerm_storage_account.unity_catalog.name}.dfs.core.windows.net/"
      DATABRICKS_WORKSPACE_ID       = azurerm_databricks_workspace.main.workspace_id
      PROJETO                       = var.projeto
      AMBIENTE                      = var.ambiente
      AZURE_REGION                  = var.location
    }
  }
}
```

## Recursos Criados

Ap√≥s a execu√ß√£o dos scripts, ser√£o criados:

### Unity Catalog
- **Metastore**: `unity-catalog-{region}`
- **Catalog**: `{projeto}_{ambiente}`
- **Schemas**:
  - `bronze` - Dados brutos
  - `silver` - Dados processados
  - `gold` - Dados refinados
  - `workspace` - Dados de workspace

### Serverless
- **Compute**: Habilitado para o workspace
- **SQL Warehouse**: `{projeto}-{ambiente}-warehouse`
  - Tamanho: 2X-Small
  - Auto-stop: 10 minutos
  - Photon habilitado
  - Spot instances para otimiza√ß√£o de custos

## Troubleshooting

### Erro: "Import requests could not be resolved"
```bash
pip install requests
```

### Erro: "curl command not found"
```bash
# Ubuntu/Debian
sudo apt-get install curl

# CentOS/RHEL
sudo yum install curl
```

### Erro: "jq command not found"
```bash
# Ubuntu/Debian
sudo apt-get install jq

# MacOS
brew install jq

# Windows: Download em https://stedolan.github.io/jq/download/
```

### Erro: "Unauthorized" (401)
- Verificar se o `DATABRICKS_ACCESS_TOKEN` est√° correto
- Verificar se o token tem permiss√µes de administrador
- Verificar se o workspace URL est√° correto

### Erro: "Metastore already exists"
- Normal se executar o script novamente
- O script tentar√° usar o metastore existente

## Logs e Monitoramento

Os scripts fornecem logs detalhados durante a execu√ß√£o:
- ‚úÖ Opera√ß√µes bem-sucedidas
- ‚ö†Ô∏è Avisos (recursos j√° existentes)
- ‚ùå Erros com detalhes da API
- üìã Resumo final da configura√ß√£o

## Seguran√ßa

**‚ö†Ô∏è Importante:**
- Nunca commitar tokens de acesso no c√≥digo
- Usar vari√°veis de ambiente ou Azure Key Vault
- Limitar permiss√µes do token ao m√≠nimo necess√°rio
- Rotacionar tokens regularmente
